{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VGG_path = os.path.join('data', 'imagenet-vgg-verydeep-19.mat')\n",
    "VGG_raw = scipy.io.loadmat(VGG_path)\n",
    "VGG_net = VGG_raw['layers'][0]\n",
    "mean_pixels = VGG_raw['meta'][0][0][2][0][0][2][0][0]\n",
    "\n",
    "'''\n",
    "VGG_net[x][0][0][y][0]\n",
    "\n",
    "x: Layer number\n",
    "\n",
    "y = 0: Name of layer\n",
    "y = 1: Type of layer {conv, relu, pool}\n",
    "y = 2: Value in layer {weights and biases, 0, type of pooling}\n",
    "'''\n",
    "\n",
    "def get_weights(vgg, layer):\n",
    "    weights = tf.constant(vgg[layer][0][0][2][0][0])\n",
    "    temp = vgg[layer][0][0][2][0][1]\n",
    "    biases = tf.constant(np.reshape(temp, (temp.size)))\n",
    "    return weights, biases\n",
    "\n",
    "def pooling_type(vgg, layer):\n",
    "    return vgg[layer][0][0][2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convolution(layer_input, weights, biases):\n",
    "    conv = tf.nn.conv2d(layer_input, weights, [1, 1, 1, 1], padding='SAME')\n",
    "    conv = conv + biases\n",
    "    return conv\n",
    "\n",
    "def relu(layer_input):\n",
    "    reLU = tf.nn.relu(layer_input)\n",
    "    return reLU\n",
    "\n",
    "def pool(layer_input, pooling_type):\n",
    "    if pooling_type == 'max':\n",
    "        pooling = tf.nn.max_pool(layer_input, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    else:\n",
    "        pooling = tf.nn.avg_pool(layer_input, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    return pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Process images\n",
    "'''\n",
    "style_img_path = os.path.join('images', 'starry_night.jpg')\n",
    "content_img_path = os.path.join('images', 'new_york.jpg')\n",
    "\n",
    "def preprocess(img):\n",
    "    # Change BGR to RGB\n",
    "    img = img[...,::-1]\n",
    "    # Reshape (h, w, d) to (1, h, w, d)\n",
    "    img = img[np.newaxis,:,:,:]\n",
    "    img = img - np.array(mean_pixels).reshape((1,1,1,3))\n",
    "    return img\n",
    "\n",
    "def postprocess(img):\n",
    "    img += np.array(mean_pixels).reshape((1,1,1,3))\n",
    "    # Reshape (1, h, w, d) to (h, w, d)\n",
    "    img = img[0]\n",
    "    img = np.clip(img, 0, 255).astype('uint8')\n",
    "    # RGB to BGR\n",
    "    img = img[...,::-1]\n",
    "    return img\n",
    "\n",
    "def read_img(img_path):\n",
    "    img = Image.open(img_path)\n",
    "    img = np.asarray(img, dtype=np.uint8)\n",
    "    img = preprocess(img)\n",
    "    return img\n",
    "\n",
    "style_image = read_img(style_img_path)\n",
    "content_image = read_img(content_img_path)\n",
    "\n",
    "style_shape = np.shape(style_image)\n",
    "content_shape = np.shape(content_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Build network\n",
    "    conv1_1, relu1_1, conv1_2, relu1_2, pool1\n",
    "    conv2_1, relu2_1, conv2_2, relu2_2, pool2\n",
    "    conv3_1, relu3_1, conv3_2, relu3_2, conv3_3, relu3_3, conv3_4, relu3_4, pool2\n",
    "    conv4_1, relu4_1, conv4_2, relu4_2, conv4_3, relu4_3, conv4_4, relu4_4, pool2\n",
    "    conv5_1, relu5_1, conv5_2, relu5_2, conv5_3, relu5_3, conv5_4, relu5_4, pool2\n",
    "'''\n",
    "\n",
    "def build_network(image, vgg):\n",
    "    net = {}\n",
    "    net['input'] = image\n",
    "    \n",
    "    # Layer 1\n",
    "    print(\"Building LAYER 1...\")\n",
    "    W, b = get_weights(vgg, 0)\n",
    "    net['conv1_1'] = convolution(net['input'], W, b)\n",
    "    net['relu1_1'] = relu(net['conv1_1'])\n",
    "    W, b = get_weights(vgg, 2)\n",
    "    net['conv1_2'] = convolution(net['relu1_1'], W, b)\n",
    "    net['relu1_2'] = relu(net['conv1_2'])\n",
    "    pooling = pooling_type(vgg, 4)\n",
    "    net['pool1'] = pool(net['relu1_2'], pooling)\n",
    "    \n",
    "    # Layer 2\n",
    "    print(\"Building LAYER 2...\")\n",
    "    W, b = get_weights(vgg, 5)\n",
    "    net['conv2_1'] = convolution(net['pool1'], W, b)\n",
    "    net['relu2_1'] = relu(net['conv2_1'])\n",
    "    W, b = get_weights(vgg, 7)\n",
    "    net['conv2_2'] = convolution(net['relu2_1'], W, b)\n",
    "    net['relu2_2'] = relu(net['conv2_2'])\n",
    "    pooling = pooling_type(vgg, 9)\n",
    "    net['pool2'] = pool(net['relu2_2'], pooling)\n",
    "    \n",
    "    # Layer 3\n",
    "    print(\"Building LAYER 3...\")\n",
    "    W, b = get_weights(vgg, 10)\n",
    "    net['conv3_1'] = convolution(net['pool2'], W, b)\n",
    "    net['relu3_1'] = relu(net['conv3_1'])\n",
    "    W, b = get_weights(vgg, 12)\n",
    "    net['conv3_2'] = convolution(net['relu3_1'], W, b)\n",
    "    net['relu3_2'] = relu(net['conv3_2'])\n",
    "    W, b = get_weights(vgg, 14)\n",
    "    net['conv3_3'] = convolution(net['relu3_2'], W, b)\n",
    "    net['relu3_3'] = relu(net['conv3_3'])\n",
    "    W, b = get_weights(vgg, 16)\n",
    "    net['conv3_4'] = convolution(net['relu3_3'], W, b)\n",
    "    net['relu3_4'] = relu(net['conv3_4'])\n",
    "    pooling = pooling_type(vgg, 18)\n",
    "    net['pool3'] = pool(net['relu3_4'], pooling)\n",
    "    \n",
    "    # Layer 4\n",
    "    print(\"Building LAYER 4...\")\n",
    "    W, b = get_weights(vgg, 19)\n",
    "    net['conv4_1'] = convolution(net['pool3'], W, b)\n",
    "    net['relu4_1'] = relu(net['conv4_1'])\n",
    "    W, b = get_weights(vgg, 21)\n",
    "    net['conv4_2'] = convolution(net['relu4_1'], W, b)\n",
    "    net['relu4_2'] = relu(net['conv4_2'])\n",
    "    W, b = get_weights(vgg, 23)\n",
    "    net['conv4_3'] = convolution(net['relu4_2'], W, b)\n",
    "    net['relu4_3'] = relu(net['conv4_3'])\n",
    "    W, b = get_weights(vgg, 25)\n",
    "    net['conv4_4'] = convolution(net['relu4_3'], W, b)\n",
    "    net['relu4_4'] = relu(net['conv4_4'])\n",
    "    pooling = pooling_type(vgg, 27)\n",
    "    net['pool4'] = pool(net['relu4_4'], pooling)\n",
    "    \n",
    "    # Layer 5\n",
    "    print(\"Building LAYER 5...\")\n",
    "    W, b = get_weights(vgg, 28)\n",
    "    net['conv5_1'] = convolution(net['pool4'], W, b)\n",
    "    net['relu5_1'] = relu(net['conv5_1'])\n",
    "    W, b = get_weights(vgg, 30)\n",
    "    net['conv5_2'] = convolution(net['relu5_1'], W, b)\n",
    "    net['relu5_2'] = relu(net['conv5_2'])\n",
    "    W, b = get_weights(vgg, 32)\n",
    "    net['conv5_3'] = convolution(net['relu5_2'], W, b)\n",
    "    net['relu5_3'] = relu(net['conv5_3'])\n",
    "    W, b = get_weights(vgg, 34)\n",
    "    net['conv5_4'] = convolution(net['relu5_3'], W, b)\n",
    "    net['relu5_4'] = relu(net['conv5_4'])\n",
    "    pooling = pooling_type(vgg, 36)\n",
    "    net['pool5'] = pool(net['relu5_4'], pooling)\n",
    "    \n",
    "    \n",
    "    print(\"... Finished Building\")\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building LAYER 1...\n",
      "Building LAYER 2...\n",
      "Building LAYER 3...\n",
      "Building LAYER 4...\n",
      "Building LAYER 5...\n",
      "... Finished Building\n",
      "Building LAYER 1...\n",
      "Building LAYER 2...\n",
      "Building LAYER 3...\n",
      "Building LAYER 4...\n",
      "Building LAYER 5...\n",
      "... Finished Building\n"
     ]
    }
   ],
   "source": [
    "CONTENT_LAYERS = ('relu4_2', 'relu5_2')\n",
    "STYLE_LAYERS = ('relu1_1', 'relu2_1', 'relu3_1', 'relu4_1', 'relu5_1')\n",
    "\n",
    "content = {}\n",
    "style = {}\n",
    "\n",
    "# Graph to compute content and style features\n",
    "feature_g = tf.Graph()\n",
    "with feature_g.as_default(), tf.device('/cpu:0'):\n",
    "    \n",
    "    # Placeholder for images\n",
    "    content_img = tf.placeholder(tf.float32, shape=content_shape)\n",
    "    style_img = tf.placeholder(tf.float32, shape=style_shape)\n",
    "    \n",
    "    # VGG nets\n",
    "    content_net = build_network(content_img, VGG_net)\n",
    "    style_net = build_network(style_img, VGG_net)\n",
    "    \n",
    "# Run graph and compute features\n",
    "with tf.Session(graph=feature_g) as session:\n",
    "    for layer in CONTENT_LAYERS:\n",
    "        content[layer] = content_net[layer].eval(feed_dict={content_img: content_image, style_img: style_image})\n",
    "    for layer in STYLE_LAYERS:\n",
    "        style[layer] = style_net[layer].eval(feed_dict={content_img: content_image, style_img: style_image})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building LAYER 1...\n",
      "Building LAYER 2...\n",
      "Building LAYER 3...\n",
      "Building LAYER 4...\n",
      "Building LAYER 5...\n",
      "... Finished Building\n",
      "Initialized\n",
      "Iteration: %d 0\n"
     ]
    }
   ],
   "source": [
    "iterations = 500\n",
    "\n",
    "# Graph for stylizing image\n",
    "style_g = tf.Graph()\n",
    "with style_g.as_default(), tf.device('/cpu:0'):\n",
    "    \n",
    "    # Initialize output image\n",
    "    output_img = tf.Variable(tf.random_normal(content_shape))\n",
    "    net = build_network(output_img, VGG_net)\n",
    "    \n",
    "    # Content Loss\n",
    "    content_losses = []\n",
    "    for content_layer in CONTENT_LAYERS:\n",
    "        content_losses.append(tf.nn.l2_loss(net[content_layer] - content[content_layer]))\n",
    "    L_content = tf.reduce_sum(content_losses)\n",
    "    \n",
    "    # Style Loss\n",
    "    style_losses = []\n",
    "    for style_layer in STYLE_LAYERS:\n",
    "        layer = net[style_layer]\n",
    "        _, height, width, number = map(lambda i: i.value, layer.get_shape())\n",
    "        size = height * width * number\n",
    "        features = tf.reshape(layer, (-1, number))\n",
    "        gram = tf.matmul(tf.transpose(features), features) / size\n",
    "        style_features = tf.reshape(style[style_layer], (-1, number))\n",
    "        style_gram = tf.matmul(tf.transpose(style_features), style_features) / size\n",
    "        style_losses.append(0.5 * tf.nn.l2_loss(gram - style_gram) / np.asarray(style_gram).size)\n",
    "    L_style = tf.reduce_sum(style_losses)\n",
    "    \n",
    "    # Total Loss\n",
    "    alpha = 0.5 # content weight\n",
    "    beta = 0.5 # style weight\n",
    "    L_total = alpha * L_content + beta * L_style\n",
    "    \n",
    "    # Optimization\n",
    "    learning_rate = 1e1\n",
    "    beta1 = 0.9\n",
    "    beta2 = 0.99\n",
    "    epsilon = 1e-08\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate, beta1, beta2, epsilon).minimize(L_total)\n",
    "    \n",
    "    def progress():\n",
    "        print(\"\\tContent Loss: %g\", L_content.eval())\n",
    "        print(\"\\t  Style Loss: %g\", L_style.eval())\n",
    "        print(\"\\t  Total Loss: %g\", L_total.eval())\n",
    "        \n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        print(\"Initialized\")\n",
    "        for step in range(iterations):\n",
    "            print(\"Iteration: \", step)\n",
    "            optimizer.run()\n",
    "            if (steps % 50 == 0):\n",
    "                progress()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
