{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VGG_path = os.path.join('data', 'imagenet-vgg-verydeep-19.mat')\n",
    "VGG_raw = scipy.io.loadmat(VGG_path)\n",
    "VGG_net = VGG_raw['layers'][0]\n",
    "mean_pixels = VGG_raw['meta'][0][0][2][0][0][2][0][0]\n",
    "\n",
    "'''\n",
    "VGG_net[x][0][0][y][0]\n",
    "\n",
    "x: Layer number\n",
    "\n",
    "y = 0: Name of layer\n",
    "y = 1: Type of layer {conv, relu, pool}\n",
    "y = 2: Value in layer {weights and biases, 0, type of pooling}\n",
    "'''\n",
    "\n",
    "def get_weights(vgg, layer):\n",
    "    weights = tf.constant(vgg[layer][0][0][2][0][0])\n",
    "    temp = vgg[layer][0][0][2][0][1]\n",
    "    biases = tf.constant(np.reshape(temp, (temp.size)))\n",
    "    return weights, biases\n",
    "\n",
    "def pooling_type(vgg, layer):\n",
    "    return vgg[layer][0][0][2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convolution(layer_input, weights, biases):\n",
    "    conv = tf.nn.conv2d(layer_input, weights, [1, 1, 1, 1], padding='SAME')\n",
    "    conv = conv + biases\n",
    "    return conv\n",
    "\n",
    "def relu(layer_input):\n",
    "    reLU = tf.nn.relu(layer_input)\n",
    "    return reLU\n",
    "\n",
    "def pool(layer_input, pooling_type):\n",
    "    if pooling_type == 'max':\n",
    "        pooling = tf.nn.max_pool(layer_input, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    else:\n",
    "        pooling = tf.nn.avg_pool(layer_input, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    return pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Build network\n",
    "    conv1_1, relu1_1, conv1_2, relu1_2, pool1\n",
    "    conv2_1, relu2_1, conv2_2, relu2_2, pool2\n",
    "    conv3_1, relu3_1, conv3_2, relu3_2, conv3_3, relu3_3, conv3_4, relu3_4, pool2\n",
    "    conv4_1, relu4_1, conv4_2, relu4_2, conv4_3, relu4_3, conv4_4, relu4_4, pool2\n",
    "    conv5_1, relu5_1, conv5_2, relu5_2, conv5_3, relu5_3, conv5_4, relu5_4, pool2\n",
    "'''\n",
    "\n",
    "def build_network(image, vgg):\n",
    "    net = {}\n",
    "    net['input'] = image\n",
    "    \n",
    "    # Layer 1\n",
    "    print(\"Building LAYER 1...\")\n",
    "    W, b = get_weights(vgg, 0)\n",
    "    net['conv1_1'] = convolution(net['input'], W, b)\n",
    "    net['relu1_1'] = relu(net['conv1_1'])\n",
    "    W, b = get_weights(vgg, 2)\n",
    "    net['conv1_2'] = convolution(net['relu1_1'], W, b)\n",
    "    net['relu1_2'] = relu(net['conv1_2'])\n",
    "    pooling = pooling_type(vgg, 4)\n",
    "    net['pool1'] = pool(net['relu1_2'], pooling)\n",
    "    \n",
    "    # Layer 2\n",
    "    print(\"Building LAYER 2...\")\n",
    "    W, b = get_weights(vgg, 5)\n",
    "    net['conv2_1'] = convolution(net['pool1'], W, b)\n",
    "    net['relu2_1'] = relu(net['conv2_1'])\n",
    "    W, b = get_weights(vgg, 7)\n",
    "    net['conv2_2'] = convolution(net['relu2_1'], W, b)\n",
    "    net['relu2_2'] = relu(net['conv2_2'])\n",
    "    pooling = pooling_type(vgg, 9)\n",
    "    net['pool2'] = pool(net['relu2_2'], pooling)\n",
    "    \n",
    "    # Layer 3\n",
    "    print(\"Building LAYER 3...\")\n",
    "    W, b = get_weights(vgg, 10)\n",
    "    net['conv3_1'] = convolution(net['pool2'], W, b)\n",
    "    net['relu3_1'] = relu(net['conv3_1'])\n",
    "    W, b = get_weights(vgg, 12)\n",
    "    net['conv3_2'] = convolution(net['relu3_1'], W, b)\n",
    "    net['relu3_2'] = relu(net['conv3_2'])\n",
    "    W, b = get_weights(vgg, 14)\n",
    "    net['conv3_3'] = convolution(net['relu3_2'], W, b)\n",
    "    net['relu3_3'] = relu(net['conv3_3'])\n",
    "    W, b = get_weights(vgg, 16)\n",
    "    net['conv3_4'] = convolution(net['relu3_3'], W, b)\n",
    "    net['relu3_4'] = relu(net['conv3_4'])\n",
    "    pooling = pooling_type(vgg, 18)\n",
    "    net['pool3'] = pool(net['relu3_4'], pooling)\n",
    "    \n",
    "    # Layer 4\n",
    "    print(\"Building LAYER 4...\")\n",
    "    W, b = get_weights(vgg, 19)\n",
    "    net['conv4_1'] = convolution(net['pool3'], W, b)\n",
    "    net['relu4_1'] = relu(net['conv4_1'])\n",
    "    W, b = get_weights(vgg, 21)\n",
    "    net['conv4_2'] = convolution(net['relu4_1'], W, b)\n",
    "    net['relu4_2'] = relu(net['conv4_2'])\n",
    "    W, b = get_weights(vgg, 23)\n",
    "    net['conv4_3'] = convolution(net['relu4_2'], W, b)\n",
    "    net['relu4_3'] = relu(net['conv4_3'])\n",
    "    W, b = get_weights(vgg, 25)\n",
    "    net['conv4_4'] = convolution(net['relu4_3'], W, b)\n",
    "    net['relu4_4'] = relu(net['conv4_4'])\n",
    "    pooling = pooling_type(vgg, 27)\n",
    "    net['pool4'] = pool(net['relu4_4'], pooling)\n",
    "    \n",
    "    # Layer 5\n",
    "    print(\"Building LAYER 5...\")\n",
    "    W, b = get_weights(vgg, 28)\n",
    "    net['conv5_1'] = convolution(net['pool4'], W, b)\n",
    "    net['relu5_1'] = relu(net['conv5_1'])\n",
    "    W, b = get_weights(vgg, 30)\n",
    "    net['conv5_2'] = convolution(net['relu5_1'], W, b)\n",
    "    net['relu5_2'] = relu(net['conv5_2'])\n",
    "    W, b = get_weights(vgg, 32)\n",
    "    net['conv5_3'] = convolution(net['relu5_2'], W, b)\n",
    "    net['relu5_3'] = relu(net['conv5_3'])\n",
    "    W, b = get_weights(vgg, 34)\n",
    "    net['conv5_4'] = convolution(net['relu5_3'], W, b)\n",
    "    net['relu5_4'] = relu(net['conv5_4'])\n",
    "    pooling = pooling_type(vgg, 36)\n",
    "    net['pool5'] = pool(net['relu5_4'], pooling)\n",
    "    \n",
    "    \n",
    "    print(\"... Finished Building\")\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Process images\n",
    "'''\n",
    "style_img_path = os.path.join('images', 'style_1.jpg')\n",
    "content_img_path = os.path.join('images', 'content_2.jpg')\n",
    "\n",
    "def preprocess(img):\n",
    "    # Change BGR to RGB\n",
    "    img = img[...,::-1]\n",
    "    # Reshape (h, w, d) to (1, h, w, d)\n",
    "    img = img[np.newaxis,:,:,:]\n",
    "    img = img - np.array(mean_pixels).reshape((1,1,1,3))\n",
    "    return img\n",
    "\n",
    "def postprocess(img):\n",
    "    img += np.array(mean_pixels).reshape((1,1,1,3))\n",
    "    # Reshape (1, h, w, d) to (h, w, d)\n",
    "    img = img[0]\n",
    "    img = np.clip(img, 0, 255).astype('uint8')\n",
    "    # RGB to BGR\n",
    "    img = img[...,::-1]\n",
    "    return img\n",
    "\n",
    "def read_img(img_path):\n",
    "    img = Image.open(img_path)\n",
    "    img = np.asarray(img, dtype=np.uint8)\n",
    "    img = preprocess(img)\n",
    "    return img\n",
    "\n",
    "style_image = read_img(style_img_path)\n",
    "content_image = read_img(content_img_path)\n",
    "\n",
    "style_shape = np.shape(style_image)\n",
    "content_shape = np.shape(content_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(style_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building LAYER 1...\n",
      "Building LAYER 2...\n",
      "Building LAYER 3...\n",
      "Building LAYER 4...\n",
      "Building LAYER 5...\n",
      "... Finished Building\n"
     ]
    }
   ],
   "source": [
    "CONTENT_LAYERS = ('relu4_2', 'relu5_2')\n",
    "STYLE_LAYERS = ('relu1_1', 'relu2_1', 'relu3_1', 'relu4_1', 'relu5_1')\n",
    "\n",
    "content = {}\n",
    "style = {}\n",
    "\n",
    "# Graph to compute content and style features\n",
    "feature_g = tf.Graph()\n",
    "with feature_g.as_default():\n",
    "    \n",
    "    img = tf.placeholder(tf.float32, shape=content_shape) # Placeholder for image\n",
    "    net = build_network(img, VGG_net) # VGG net\n",
    "    \n",
    "# Run graph and compute features\n",
    "with tf.Session(graph=feature_g) as session:\n",
    "    for layer in CONTENT_LAYERS:\n",
    "        content[layer] = net[layer].eval(feed_dict={img: content_image})\n",
    "    for layer in STYLE_LAYERS:\n",
    "        feats = net[layer].eval(feed_dict={img: style_image})\n",
    "        feats = np.reshape(feats, (-1, feats.shape[3]))\n",
    "        gram = np.matmul(feats.T, feats) / feats.size\n",
    "        style[layer] = gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building LAYER 1...\n",
      "Building LAYER 2...\n",
      "Building LAYER 3...\n",
      "Building LAYER 4...\n",
      "Building LAYER 5...\n",
      "... Finished Building\n",
      "Initialized\n",
      "\tIteration:  0\n",
      "\t\tTotal Loss:  8.28898e+07\n",
      "\tIteration:  100\n",
      "\t\tTotal Loss:  5.01038e+06\n",
      "\tIteration:  200\n",
      "\t\tTotal Loss:  4.16382e+06\n",
      "\tIteration:  300\n",
      "\t\tTotal Loss:  3.89903e+06\n",
      "\tIteration:  400\n",
      "\t\tTotal Loss:  3.76921e+06\n",
      "\tIteration:  500\n",
      "\t\tTotal Loss:  3.68845e+06\n",
      "\tIteration:  600\n",
      "\t\tTotal Loss:  3.62852e+06\n",
      "\tIteration:  700\n",
      "\t\tTotal Loss:  3.59274e+06\n",
      "\tIteration:  800\n",
      "\t\tTotal Loss:  3.55846e+06\n",
      "\tIteration:  900\n",
      "\t\tTotal Loss:  3.54015e+06\n",
      "\tIteration:  1000\n",
      "\t\tTotal Loss:  3.52452e+06\n",
      "\tIteration:  1100\n",
      "\t\tTotal Loss:  3.51903e+06\n",
      "\tIteration:  1200\n",
      "\t\tTotal Loss:  3.50018e+06\n",
      "\tIteration:  1300\n",
      "\t\tTotal Loss:  3.55529e+06\n",
      "\tIteration:  1400\n",
      "\t\tTotal Loss:  3.47047e+06\n",
      "\tIteration:  1500\n",
      "\t\tTotal Loss:  3.47129e+06\n",
      "Finished optimizing. Saving checkpoint.\n",
      "Finished saving checkpoint.\n"
     ]
    }
   ],
   "source": [
    "iterations = 1501\n",
    "\n",
    "# Graph for stylizing image\n",
    "style_g = tf.Graph()\n",
    "with style_g.as_default():\n",
    "    \n",
    "    # Initialize output image\n",
    "    output_img = tf.Variable(tf.random_normal(content_shape))\n",
    "    net = build_network(output_img, VGG_net)\n",
    "    \n",
    "    # Content Loss\n",
    "    content_losses = []\n",
    "    content_blend = {}\n",
    "    content_blend['relu4_2'] = 1.0\n",
    "    content_blend['relu5_2'] = 0.0\n",
    "    for content_layer in CONTENT_LAYERS:\n",
    "        content_losses.append(content_blend[content_layer] * \n",
    "            (tf.nn.l2_loss(net[content_layer] - content[content_layer])) / np.asarray(content[content_layer]).size)\n",
    "    L_content = tf.reduce_sum(content_losses)\n",
    "    \n",
    "    # Style Loss\n",
    "    style_losses = []\n",
    "    for style_layer in STYLE_LAYERS:\n",
    "        layer = net[style_layer]\n",
    "        _, height, width, number = map(lambda i: i.value, layer.get_shape())\n",
    "        size = height * width * number\n",
    "        features = tf.reshape(layer, (-1, number))\n",
    "        gram = tf.matmul(tf.transpose(features), features) / size\n",
    "        style_losses.append(0.5 * tf.nn.l2_loss(gram - style[style_layer]) / np.asarray(style[style_layer]).size)\n",
    "    L_style = tf.reduce_sum(style_losses)\n",
    "    \n",
    "    # Total Loss\n",
    "    alpha = 50 # content weight\n",
    "    beta = 400 # style weight\n",
    "    L_total = alpha * L_content + beta * L_style\n",
    "    \n",
    "    # Optimization\n",
    "    learning_rate = 3e0\n",
    "    beta1 = 0.9\n",
    "    beta2 = 0.999\n",
    "    epsilon = 1e-08\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate, beta1, beta2, epsilon).minimize(L_total)\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    def progress():\n",
    "        print(\"\\t\\tTotal Loss: \", L_total.eval())\n",
    "        \n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        print(\"Initialized\")\n",
    "        for step in range(iterations):\n",
    "            optimizer.run()\n",
    "            if (step % 100 == 0):\n",
    "                print(\"\\tIteration: \", step)\n",
    "                progress()\n",
    "        print(\"Finished optimizing. Saving checkpoint.\")\n",
    "        save_path = saver.save(sess, \"./.ckpt/test-run.ckpt\")\n",
    "        print(\"Finished saving checkpoint.\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring checkpoint.\n",
      "INFO:tensorflow:Restoring parameters from ./.ckpt/test-run.ckpt\n",
      "Restored image.\n",
      "Output image generated.\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=style_g) as sess:\n",
    "    print(\"Restoring checkpoint.\")\n",
    "    saver.restore(sess, \"./.ckpt/test-run.ckpt\")\n",
    "    op_img = tf.cast(output_img, dtype=np.float64).eval()\n",
    "    print(\"Restored image.\")\n",
    "\n",
    "op_img = postprocess(op_img)\n",
    "op_img = Image.fromarray(op_img)\n",
    "op_img.save(\"./output/output-6.jpg\")\n",
    "print(\"Output image generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
